{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification: Titanic Dataset\n",
    "https://www.kaggle.com/c/titanic\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Dataset Information:\n",
    "\n",
    "\n",
    "\n",
    "Attribute Information: (9 features and 1 class)\n",
    "\n",
    "Variable Definition Key\n",
    "\n",
    "    survival Survival 0 = No, 1 = Yes\n",
    "    pclass Ticket class 1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "    sex Sex\n",
    "    Age Age in years\n",
    "    sibsp # of siblings / spouses aboard the Titanic\n",
    "    parch # of parents / children aboard the Titanic\n",
    "    ticket Ticket number\n",
    "    fare Passenger fare\n",
    "    cabin Cabin number\n",
    "    embarked Port of Embarkation C = Cherbourg, Q = Queenstown, S = Southampton\n",
    "\n",
    "Objective of this project\n",
    "\n",
    "\n",
    "\n",
    "** Dataset Information: **\n",
    "\n",
    "891 passenger information aboard the Titanic\n",
    "\n",
    "** Attribute Information: (9 features and 1 class)**\n",
    "\n",
    "- survival Survival 0 = No, 1 = Yes\n",
    "- pclass Ticket class 1 = 1st, 2 = 2nd, 3 = 3rd\n",
    "- sex Sex\n",
    "- Age Age in years\n",
    "- sibsp # of siblings / spouses aboard the Titanic\n",
    "- parch # of parents / children aboard the Titanic\n",
    "- ticket Ticket number\n",
    "- fare Passenger fare\n",
    "- cabin Cabin number\n",
    "- embarked Port of Embarkation C = Cherbourg, Q = Queenstown, S = Southampton\n",
    "\n",
    "\n",
    "** Objective of this project **\n",
    "\n",
    "predict whether a passenger survived the sinking of the Titanic or not"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init('/home/danny/spark-2.2.1-bin-hadoop2.7')\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName('titanic').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- PassengerId: integer (nullable = true)\n",
      " |-- Survived: integer (nullable = true)\n",
      " |-- Pclass: integer (nullable = true)\n",
      " |-- Name: string (nullable = true)\n",
      " |-- Sex: string (nullable = true)\n",
      " |-- Age: double (nullable = true)\n",
      " |-- SibSp: integer (nullable = true)\n",
      " |-- Parch: integer (nullable = true)\n",
      " |-- Ticket: string (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Cabin: string (nullable = true)\n",
      " |-- Embarked: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "df = spark.read.csv('titanic.csv',inferSchema=True,header=True)\n",
    "# Inspect Data\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|PassengerId|Survived|Pclass|                Name|   Sex| Age|SibSp|Parch|          Ticket|   Fare|Cabin|Embarked|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "|          1|       0|     3|Braund, Mr. Owen ...|  male|22.0|    1|    0|       A/5 21171|   7.25| null|       S|\n",
      "|          2|       1|     1|Cumings, Mrs. Joh...|female|38.0|    1|    0|        PC 17599|71.2833|  C85|       C|\n",
      "|          3|       1|     3|Heikkinen, Miss. ...|female|26.0|    0|    0|STON/O2. 3101282|  7.925| null|       S|\n",
      "|          4|       1|     1|Futrelle, Mrs. Ja...|female|35.0|    1|    0|          113803|   53.1| C123|       S|\n",
      "|          5|       0|     3|Allen, Mr. Willia...|  male|35.0|    0|    0|          373450|   8.05| null|       S|\n",
      "+-----------+--------+------+--------------------+------+----+-----+-----+----------------+-------+-----+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(PassengerId=1, Survived=0, Pclass=3, Name='Braund, Mr. Owen Harris', Sex='male', Age=22.0, SibSp=1, Parch=0, Ticket='A/5 21171', Fare=7.25, Cabin=None, Embarked='S')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
      "|summary|      PassengerId|           Survived|            Pclass|                Name|   Sex|               Age|             SibSp|              Parch|            Ticket|             Fare|Cabin|Embarked|\n",
      "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
      "|  count|              891|                891|               891|                 891|   891|               714|               891|                891|               891|              891|  204|     889|\n",
      "|   mean|            446.0| 0.3838383838383838| 2.308641975308642|                null|  null| 29.69911764705882|0.5230078563411896|0.38159371492704824|260318.54916792738| 32.2042079685746| null|    null|\n",
      "| stddev|257.3538420152301|0.48659245426485753|0.8360712409770491|                null|  null|14.526497332334035|1.1027434322934315| 0.8060572211299488|471609.26868834975|49.69342859718089| null|    null|\n",
      "|    min|                1|                  0|                 1|\"Andersson, Mr. A...|female|              0.42|                 0|                  0|            110152|              0.0|  A10|       C|\n",
      "|    max|              891|                  1|                 3|van Melkebeke, Mr...|  male|              80.0|                 8|                  6|         WE/P 5735|         512.3292|    T|       S|\n",
      "+-------+-----------------+-------------------+------------------+--------------------+------+------------------+------------------+-------------------+------------------+-----------------+-----+--------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import (StringIndexer,VectorAssembler,\n",
    "                               OneHotEncoder,StringIndexer)\n",
    "from pyspark.ml import Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Clean Data **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['PassengerId',\n",
       " 'Survived',\n",
       " 'Pclass',\n",
       " 'Name',\n",
       " 'Sex',\n",
       " 'Age',\n",
       " 'SibSp',\n",
       " 'Parch',\n",
       " 'Ticket',\n",
       " 'Fare',\n",
       " 'Cabin',\n",
       " 'Embarked']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------+----+-----+-----+-------+--------+\n",
      "|Survived|Pclass|   Sex| Age|SibSp|Parch|   Fare|Embarked|\n",
      "+--------+------+------+----+-----+-----+-------+--------+\n",
      "|       0|     3|  male|22.0|    1|    0|   7.25|       S|\n",
      "|       1|     1|female|38.0|    1|    0|71.2833|       C|\n",
      "+--------+------+------+----+-----+-----+-------+--------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "final_df = df.select(['Survived','Pclass','Sex',\n",
    "                     'Age','SibSp','Parch',\n",
    "                     'Fare','Embarked']).na.drop() \n",
    "final_df.show(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Convert categorical to numeric **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gender\n",
    "gender_indexer = StringIndexer(inputCol='Sex',outputCol='SexIndex')\n",
    "indexed = gender_indexer.fit(final_df).transform(final_df)\n",
    "gender_encoder = OneHotEncoder(inputCol='SexIndex',outputCol='SexVec')\n",
    "encoded = gender_encoder.transform(indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embark\n",
    "embark_indexer = StringIndexer(inputCol='Embarked',outputCol='EmbarkIndex')\n",
    "indexed = embark_indexer.fit(encoded).transform(encoded)\n",
    "embark_encoder = OneHotEncoder(inputCol='EmbarkIndex',outputCol='EmbarkVec')\n",
    "encoded = embark_encoder.transform(indexed)\n",
    "#encoded.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Split Features & Class (or target) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+\n",
      "|            features|Survived|\n",
      "+--------------------+--------+\n",
      "|[3.0,1.0,22.0,1.0...|       0|\n",
      "|[1.0,0.0,38.0,1.0...|       1|\n",
      "|(8,[0,2,5,6],[3.0...|       1|\n",
      "|[1.0,0.0,35.0,1.0...|       1|\n",
      "|[3.0,1.0,35.0,0.0...|       0|\n",
      "+--------------------+--------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# combine features into a single column\n",
    "assembler = VectorAssembler(inputCols=['Pclass','SexVec','Age',\n",
    "                                       'SibSp','Parch','Fare',\n",
    "                                       'EmbarkVec'],outputCol='features')\n",
    "output = assembler.transform(encoded )\n",
    "#output.show(5)\n",
    "\n",
    "# features and target\n",
    "final_data = output.select('features','Survived')\n",
    "final_data.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Split Train Test sets **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------------+\n",
      "|summary|           Survived|\n",
      "+-------+-------------------+\n",
      "|  count|                506|\n",
      "|   mean| 0.4189723320158103|\n",
      "| stddev|0.49387910015468434|\n",
      "|    min|                  0|\n",
      "|    max|                  1|\n",
      "+-------+-------------------+\n",
      "\n",
      "+-------+-------------------+\n",
      "|summary|           Survived|\n",
      "+-------+-------------------+\n",
      "|  count|                206|\n",
      "|   mean|0.36893203883495146|\n",
      "| stddev|0.48369091647024215|\n",
      "|    min|                  0|\n",
      "|    max|                  1|\n",
      "+-------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seed = 101 #for reproducibility\n",
    "train_data,test_data = final_data.randomSplit([0.7,0.3],seed=seed)\n",
    "train_data.describe().show()\n",
    "test_data.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import (LogisticRegression,LinearSVC,\n",
    "                                        DecisionTreeClassifier,GBTClassifier,\n",
    "                                        RandomForestClassifier,NaiveBayes)\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize multiple regressors\n",
    "lrc = LogisticRegression(featuresCol='features', labelCol='Survived')\n",
    "svc = LinearSVC(featuresCol='features', labelCol='Survived')\n",
    "nbc = NaiveBayes(featuresCol='features', labelCol='Survived')\n",
    "dtc = DecisionTreeClassifier(featuresCol='features', labelCol='Survived', seed=seed)\n",
    "rfc = RandomForestClassifier(featuresCol='features', labelCol='Survived', seed=seed)\n",
    "gbc = GBTClassifier(featuresCol='features', labelCol='Survived', seed=seed)\n",
    "\n",
    "# Train the models \n",
    "lrc_model = lrc.fit(train_data)\n",
    "svc_model = svc.fit(train_data)\n",
    "nbc_model = nbc.fit(train_data)\n",
    "dtc_model = dtc.fit(train_data)\n",
    "rfc_model = rfc.fit(train_data)\n",
    "gbc_model = gbc.fit(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tArea Under ROC\n",
      "Logistic Regression:\t0.872\n",
      "Support Vector Machine\t0.863\n",
      "Naive Bayes:\t\t0.407\n",
      "Decision Tree:\t\t0.697\n",
      "Random Forest:\t\t0.869\n",
      "Gradient Boosting Tree:\t0.855\n"
     ]
    }
   ],
   "source": [
    "# Make predictions\n",
    "lrc_predictions = lrc_model.transform(test_data)\n",
    "svc_predictions = svc_model.transform(test_data)\n",
    "nbc_predictions = nbc_model.transform(test_data)\n",
    "dtc_predictions = dtc_model.transform(test_data)\n",
    "rfc_predictions = rfc_model.transform(test_data)\n",
    "gbc_predictions = gbc_model.transform(test_data)\n",
    "\n",
    "# Evaluate the models\n",
    "auc_evaluator = BinaryClassificationEvaluator(rawPredictionCol='rawPrediction', \n",
    "                                              labelCol='Survived', \n",
    "                                              metricName='areaUnderROC')\n",
    "\n",
    "print('\\t\\t\\tArea Under ROC')\n",
    "print('Logistic Regression:\\t{:.3f}'.format(auc_evaluator.evaluate(lrc_predictions)))\n",
    "print('Support Vector Machine\\t{:.3f}'.format(auc_evaluator.evaluate(svc_predictions)))\n",
    "print('Naive Bayes:\\t\\t{:.3f}'.format(auc_evaluator.evaluate(nbc_predictions)))\n",
    "print('Decision Tree:\\t\\t{:.3f}'.format(auc_evaluator.evaluate(dtc_predictions)))\n",
    "print('Random Forest:\\t\\t{:.3f}'.format(auc_evaluator.evaluate(rfc_predictions)))\n",
    "print('Gradient Boosting Tree:\\t{:.3f}'.format(auc_evaluator.evaluate(gbc_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8328702444138972, 0.8328702444138972, 0.8328702444138972, 0.8304679229963117, 0.8218402691597032, 0.7527433982897498, 0.8271547871149981, 0.7527433982897498, 0.5]\n",
      "LogisticRegression_4689bb19e6378307a510\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n",
    "\n",
    "# randomforest\n",
    "model = LogisticRegression(featuresCol='features', labelCol='Survived')\n",
    "# grid params\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(model.regParam, [0.0, 0.2, 0.4]) \\\n",
    "    .addGrid(model.elasticNetParam, [0.0, 0.5 ,1.0]) \\\n",
    "    .build()\n",
    "# cross validation\n",
    "crossval = CrossValidator(estimator=model,\n",
    "                          estimatorParamMaps=paramGrid,\n",
    "                          evaluator=BinaryClassificationEvaluator(labelCol='Survived',\n",
    "                                                              metricName='areaUnderROC'),\n",
    "                          numFolds=2, # use 3+ folds in practice\n",
    "                          seed=seed)\n",
    "cvModel = crossval.fit(train_data)\n",
    "# results\n",
    "print(cvModel.avgMetrics)\n",
    "print(cvModel.bestModel) #regParam=0, elasticNetParam=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\t\tArea Under ROC\n",
      "Logistic Regression:\t0.872\n"
     ]
    }
   ],
   "source": [
    "# make predictions\n",
    "predictions = cvModel.transform(test_data)\n",
    "# calculate auc\n",
    "print('\\t\\t\\tArea Under ROC')\n",
    "print('Logistic Regression:\\t{:.3f}'.format(auc_evaluator.evaluate(predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------+--------------------+--------------------+----------+\n",
      "|            features|Survived|       rawPrediction|         probability|prediction|\n",
      "+--------------------+--------+--------------------+--------------------+----------+\n",
      "|(8,[0,1,2,5],[3.0...|       0|[2.63535923735257...|[0.93310286074356...|       0.0|\n",
      "|(8,[0,1,2,5],[3.0...|       0|[3.99628709116700...|[0.98194809251837...|       0.0|\n",
      "|(8,[0,1,2,5],[3.0...|       0|[4.22310840013608...|[0.98555858426960...|       0.0|\n",
      "|(8,[0,1,2,6],[1.0...|       0|[0.01029270015223...|[0.50257315232152...|       0.0|\n",
      "|(8,[0,1,2,6],[3.0...|       0|[2.97607252937186...|[0.95148138247997...|       0.0|\n",
      "|(8,[0,2,4,5],[3.0...|       0|[0.31454777260124...|[0.57799493092090...|       0.0|\n",
      "|(8,[0,2,5],[2.0,3...|       1|[-1.2428296044650...|[0.22394383619363...|       1.0|\n",
      "|(8,[0,2,5],[3.0,1...|       1|[-0.5390689911679...|[0.36840418521196...|       1.0|\n",
      "|(8,[0,2,5,6],[1.0...|       1|[-2.8051697862880...|[0.05704544889269...|       1.0|\n",
      "|(8,[0,2,5,6],[1.0...|       1|[-2.6133900085500...|[0.06828161806675...|       1.0|\n",
      "+--------------------+--------+--------------------+--------------------+----------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "classifier = LogisticRegression(featuresCol='features', labelCol='Survived', \n",
    "                      rawPredictionCol='rawPrediction', \n",
    "                      regParam=0.0, elasticNetParam=0.0)\n",
    "final_model = classifier.fit(train_data)\n",
    "# make predictions\n",
    "predictions = final_model.transform(test_data)\n",
    "predictions.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Area Under ROC:\t0.872\n",
      "Accuracy:\t84.0%\n",
      "\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.90      0.88       130\n",
      "          1       0.81      0.74      0.77        76\n",
      "\n",
      "avg / total       0.84      0.84      0.84       206\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f48c7f8ada0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "df_pred = predictions.toPandas()\n",
    "\n",
    "print('Area Under ROC:\\t{:.3f}'.format(auc_evaluator.evaluate(predictions)))\n",
    "print('Accuracy:\\t{:0.1f}%'.format(100*accuracy_score(df_pred['Survived'],\n",
    "                                                 df_pred['prediction'])))\n",
    "\n",
    "\n",
    "#classification report\n",
    "print('\\n')\n",
    "print(classification_report(df_pred['Survived'],df_pred['prediction']))\n",
    "\n",
    "#confusion matrix\n",
    "confmat = confusion_matrix(df_pred['Survived'],df_pred['prediction'])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(2.5, 2.5))\n",
    "ax.matshow(confmat, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(confmat.shape[0]):\n",
    "    for j in range(confmat.shape[1]):\n",
    "        ax.text(x=j, y=i, s=confmat[i, j], va='center', ha='center')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
