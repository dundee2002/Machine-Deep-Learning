{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multiclass Classification: MNIST database of handwritten digits\n",
    "https://keras.io/datasets/\n",
    "\n",
    "** Dataset Information: **\n",
    "\n",
    "Dataset of 60,000 28x28 grayscale images of the 10 digits, along with a test set of 10,000 images.\n",
    "\n",
    "** Attribute Information: (784 features and 1 class) **\n",
    "\n",
    "- 28x28 grayscale images\n",
    "- 10 digits\n",
    "\n",
    "** Objective of this project **\n",
    "\n",
    "recognizing the digits from images\n",
    "\n",
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.datasets import mnist\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (60000,) (10000, 28, 28) (10000,)\n"
     ]
    }
   ],
   "source": [
    "# Load Data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAABOCAYAAAAw9e0sAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niyACukAgELgI/w9V4gVzhRNJggAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1ba11028a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot first 9 images\n",
    "for i in range(0, 9):\n",
    "    plt.subplot(190 + (i+1))\n",
    "    plt.imshow(X_train[i], cmap=plt.get_cmap('gray'))\n",
    "    plt.title(y_train[i]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8),\n",
       " array([5923, 6742, 5958, 6131, 5842, 5421, 5918, 6265, 5851, 5949], dtype=int64))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 10 digits\n",
    "np.unique(y_train,return_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (60000, 10) (10000, 784) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Data preprocessing\n",
    "from keras.utils.np_utils import to_categorical\n",
    "seed = 101 #random seed for reproducibility\n",
    "np.random.seed(seed)\n",
    "\n",
    "# flatten 28*28 images to a 784 vector\n",
    "num_pixels = X_train.shape[1] * X_train.shape[2]\n",
    "X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32')\n",
    "X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32')\n",
    "\n",
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "# one hot encode outputs\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 784)               615440    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                7850      \n",
      "=================================================================\n",
      "Total params: 623,290\n",
      "Trainable params: 623,290\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 10s - loss: 0.2776 - acc: 0.9208 - val_loss: 0.1401 - val_acc: 0.9592\n",
      "Epoch 2/10\n",
      " - 10s - loss: 0.1110 - acc: 0.9682 - val_loss: 0.0965 - val_acc: 0.9721\n",
      "Epoch 3/10\n",
      " - 10s - loss: 0.0700 - acc: 0.9800 - val_loss: 0.0785 - val_acc: 0.9763\n",
      "Epoch 4/10\n",
      " - 10s - loss: 0.0494 - acc: 0.9859 - val_loss: 0.0675 - val_acc: 0.9795\n",
      "Epoch 5/10\n",
      " - 10s - loss: 0.0365 - acc: 0.9899 - val_loss: 0.0626 - val_acc: 0.9812\n",
      "Epoch 6/10\n",
      " - 10s - loss: 0.0260 - acc: 0.9932 - val_loss: 0.0603 - val_acc: 0.9808\n",
      "Epoch 7/10\n",
      " - 10s - loss: 0.0192 - acc: 0.9952 - val_loss: 0.0594 - val_acc: 0.9815\n",
      "Epoch 8/10\n",
      " - 10s - loss: 0.0146 - acc: 0.9967 - val_loss: 0.0618 - val_acc: 0.9814\n",
      "Epoch 9/10\n",
      " - 10s - loss: 0.0115 - acc: 0.9974 - val_loss: 0.0584 - val_acc: 0.9828\n",
      "Epoch 10/10\n",
      " - 10s - loss: 0.0076 - acc: 0.9988 - val_loss: 0.0620 - val_acc: 0.9816\n",
      "loss of train set: 0.007\n",
      "accuracy of train set: 99.9%\n",
      "loss of test set: 0.062\n",
      "accuracy of test set: 98.2%\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "# define the model\n",
    "def create_model():   \n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(num_pixels, input_dim=num_pixels, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model\n",
    "# build the model\n",
    "model = create_model()\n",
    "# train the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), \n",
    "          epochs=10, batch_size=200, verbose=2)\n",
    "\n",
    "# evaluate model on train set\n",
    "scores = model.evaluate(X_train,y_train,verbose=0)\n",
    "print('loss of train set: {:0.3f}'.format(scores[0]))\n",
    "print('accuracy of train set: {:0.1f}%'.format(scores[1]*100))\n",
    "# evaluate model on test data\n",
    "scores = model.evaluate(X_test,y_test,verbose=0)\n",
    "print('loss of test set: {:0.3f}'.format(scores[0]))\n",
    "print('accuracy of test set: {:0.1f}%'.format(scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1) (60000, 10) (10000, 28, 28, 1) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "# load data\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Data preprocessing\n",
    "# reshape to [samples][width][height][pixels]\n",
    "X_train = X_train.reshape(-1, 28, 28, 1).astype('float32')\n",
    "X_test = X_test.reshape(-1, 28, 28, 1).astype('float32')\n",
    "\n",
    "# normalize inputs from 0-255 to 0-1\n",
    "X_train = X_train / 255\n",
    "X_test = X_test / 255\n",
    "\n",
    "# one hot encode outputs\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "num_classes = y_test.shape[1]\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 1600)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               204928    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 50)                6450      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                510       \n",
      "=================================================================\n",
      "Total params: 230,704\n",
      "Trainable params: 230,704\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      " - 81s - loss: 0.2797 - acc: 0.9152 - val_loss: 0.0767 - val_acc: 0.9746\n",
      "Epoch 2/10\n",
      " - 85s - loss: 0.0702 - acc: 0.9783 - val_loss: 0.0415 - val_acc: 0.9853\n",
      "Epoch 3/10\n",
      " - 87s - loss: 0.0472 - acc: 0.9851 - val_loss: 0.0358 - val_acc: 0.9878\n",
      "Epoch 4/10\n",
      " - 88s - loss: 0.0374 - acc: 0.9885 - val_loss: 0.0282 - val_acc: 0.9904\n",
      "Epoch 5/10\n",
      " - 80s - loss: 0.0314 - acc: 0.9899 - val_loss: 0.0292 - val_acc: 0.9895\n",
      "Epoch 6/10\n",
      " - 80s - loss: 0.0282 - acc: 0.9910 - val_loss: 0.0267 - val_acc: 0.9908\n",
      "Epoch 7/10\n",
      " - 86s - loss: 0.0230 - acc: 0.9922 - val_loss: 0.0280 - val_acc: 0.9910\n",
      "Epoch 8/10\n",
      " - 80s - loss: 0.0197 - acc: 0.9931 - val_loss: 0.0246 - val_acc: 0.9920\n",
      "Epoch 9/10\n",
      " - 76s - loss: 0.0175 - acc: 0.9945 - val_loss: 0.0244 - val_acc: 0.9924\n",
      "Epoch 10/10\n",
      " - 76s - loss: 0.0164 - acc: 0.9946 - val_loss: 0.0291 - val_acc: 0.9904\n",
      "loss of train set: 0.011\n",
      "accuracy of train set: 99.7%\n",
      "loss of test set: 0.029\n",
      "accuracy of test set: 99.0%\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "from keras.layers import Dropout,Flatten\n",
    "from keras.layers.convolutional import Conv2D,MaxPooling2D\n",
    "\n",
    "K.clear_session()\n",
    "np.random.seed(seed)\n",
    "\n",
    "# define the model\n",
    "def create_model():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(32, (3, 3), input_shape=(28, 28,1), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(50, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    print(model.summary())\n",
    "    return model\n",
    "# build the model\n",
    "model = create_model()\n",
    "\n",
    "# train the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), \n",
    "          epochs=10, batch_size=200, verbose=2)\n",
    "\n",
    "# evaluate model on train set\n",
    "scores = model.evaluate(X_train,y_train,verbose=0)\n",
    "print('loss of train set: {:0.3f}'.format(scores[0]))\n",
    "print('accuracy of train set: {:0.1f}%'.format(scores[1]*100))\n",
    "# evaluate model on test data\n",
    "scores = model.evaluate(X_test,y_test,verbose=0)\n",
    "print('loss of test set: {:0.3f}'.format(scores[0]))\n",
    "print('accuracy of test set: {:0.1f}%'.format(scores[1]*100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
