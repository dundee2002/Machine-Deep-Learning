{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Binary Classification: Breast Cancer Wisconsin Dataset\n",
    "https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Wisconsin+(Diagnostic)\n",
    "\n",
    "** Dataset Information: **\n",
    "\n",
    "characteristics of the cell nuclei from a digitized image of a fine needle aspirate (FNA) of a breast mass (total 569 instances). \n",
    "\n",
    "** Attribute Information: (30 features and 1 class)**\n",
    "\n",
    "1. ID number \n",
    "2. Diagnosis (M = malignant, B = benign)\n",
    "\n",
    "Ten real-valued features are computed for each cell nucleus: \n",
    "\n",
    "a) radius (mean of distances from center to points on the perimeter) \n",
    "b) texture (standard deviation of gray-scale values) \n",
    "c) perimeter \n",
    "d) area \n",
    "e) smoothness (local variation in radius lengths) \n",
    "f) compactness (perimeter^2 / area - 1.0) \n",
    "g) concavity (severity of concave portions of the contour) \n",
    "h) concave points (number of concave portions of the contour) \n",
    "i) symmetry \n",
    "j) fractal dimension (\"coastline approximation\" - 1)\n",
    "\n",
    "** Objective of this project **\n",
    "\n",
    "predict whether a patient's breast tumor is malignant or benign (class; M or B) based on cell nuclei characteristics (features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load Data\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data'\n",
    "df = pd.read_csv(url,header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>25.38</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>24.99</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>23.57</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>14.91</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>22.54</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 32 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0  1      2      3       4       5        6        7       8   \\\n",
       "0    842302  M  17.99  10.38  122.80  1001.0  0.11840  0.27760  0.3001   \n",
       "1    842517  M  20.57  17.77  132.90  1326.0  0.08474  0.07864  0.0869   \n",
       "2  84300903  M  19.69  21.25  130.00  1203.0  0.10960  0.15990  0.1974   \n",
       "3  84348301  M  11.42  20.38   77.58   386.1  0.14250  0.28390  0.2414   \n",
       "4  84358402  M  20.29  14.34  135.10  1297.0  0.10030  0.13280  0.1980   \n",
       "\n",
       "        9    ...        22     23      24      25      26      27      28  \\\n",
       "0  0.14710   ...     25.38  17.33  184.60  2019.0  0.1622  0.6656  0.7119   \n",
       "1  0.07017   ...     24.99  23.41  158.80  1956.0  0.1238  0.1866  0.2416   \n",
       "2  0.12790   ...     23.57  25.53  152.50  1709.0  0.1444  0.4245  0.4504   \n",
       "3  0.10520   ...     14.91  26.50   98.87   567.7  0.2098  0.8663  0.6869   \n",
       "4  0.10430   ...     22.54  16.67  152.20  1575.0  0.1374  0.2050  0.4000   \n",
       "\n",
       "       29      30       31  \n",
       "0  0.2654  0.4601  0.11890  \n",
       "1  0.1860  0.2750  0.08902  \n",
       "2  0.2430  0.3613  0.08758  \n",
       "3  0.2575  0.6638  0.17300  \n",
       "4  0.1625  0.2364  0.07678  \n",
       "\n",
       "[5 rows x 32 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Inspect Data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 32 columns):\n",
      "0     569 non-null int64\n",
      "1     569 non-null object\n",
      "2     569 non-null float64\n",
      "3     569 non-null float64\n",
      "4     569 non-null float64\n",
      "5     569 non-null float64\n",
      "6     569 non-null float64\n",
      "7     569 non-null float64\n",
      "8     569 non-null float64\n",
      "9     569 non-null float64\n",
      "10    569 non-null float64\n",
      "11    569 non-null float64\n",
      "12    569 non-null float64\n",
      "13    569 non-null float64\n",
      "14    569 non-null float64\n",
      "15    569 non-null float64\n",
      "16    569 non-null float64\n",
      "17    569 non-null float64\n",
      "18    569 non-null float64\n",
      "19    569 non-null float64\n",
      "20    569 non-null float64\n",
      "21    569 non-null float64\n",
      "22    569 non-null float64\n",
      "23    569 non-null float64\n",
      "24    569 non-null float64\n",
      "25    569 non-null float64\n",
      "26    569 non-null float64\n",
      "27    569 non-null float64\n",
      "28    569 non-null float64\n",
      "29    569 non-null float64\n",
      "30    569 non-null float64\n",
      "31    569 non-null float64\n",
      "dtypes: float64(30), int64(1), object(1)\n",
      "memory usage: 142.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5.690000e+02</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.037183e+07</td>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>...</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.250206e+08</td>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>...</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>8.670000e+03</td>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>8.692180e+05</td>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>...</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>9.060240e+05</td>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>...</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.813129e+06</td>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>...</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.113205e+08</td>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>...</td>\n",
       "      <td>36.040000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0           2           3           4            5   \\\n",
       "count  5.690000e+02  569.000000  569.000000  569.000000   569.000000   \n",
       "mean   3.037183e+07   14.127292   19.289649   91.969033   654.889104   \n",
       "std    1.250206e+08    3.524049    4.301036   24.298981   351.914129   \n",
       "min    8.670000e+03    6.981000    9.710000   43.790000   143.500000   \n",
       "25%    8.692180e+05   11.700000   16.170000   75.170000   420.300000   \n",
       "50%    9.060240e+05   13.370000   18.840000   86.240000   551.100000   \n",
       "75%    8.813129e+06   15.780000   21.800000  104.100000   782.700000   \n",
       "max    9.113205e+08   28.110000   39.280000  188.500000  2501.000000   \n",
       "\n",
       "               6           7           8           9           10     ...      \\\n",
       "count  569.000000  569.000000  569.000000  569.000000  569.000000     ...       \n",
       "mean     0.096360    0.104341    0.088799    0.048919    0.181162     ...       \n",
       "std      0.014064    0.052813    0.079720    0.038803    0.027414     ...       \n",
       "min      0.052630    0.019380    0.000000    0.000000    0.106000     ...       \n",
       "25%      0.086370    0.064920    0.029560    0.020310    0.161900     ...       \n",
       "50%      0.095870    0.092630    0.061540    0.033500    0.179200     ...       \n",
       "75%      0.105300    0.130400    0.130700    0.074000    0.195700     ...       \n",
       "max      0.163400    0.345400    0.426800    0.201200    0.304000     ...       \n",
       "\n",
       "               22          23          24           25          26  \\\n",
       "count  569.000000  569.000000  569.000000   569.000000  569.000000   \n",
       "mean    16.269190   25.677223  107.261213   880.583128    0.132369   \n",
       "std      4.833242    6.146258   33.602542   569.356993    0.022832   \n",
       "min      7.930000   12.020000   50.410000   185.200000    0.071170   \n",
       "25%     13.010000   21.080000   84.110000   515.300000    0.116600   \n",
       "50%     14.970000   25.410000   97.660000   686.500000    0.131300   \n",
       "75%     18.790000   29.720000  125.400000  1084.000000    0.146000   \n",
       "max     36.040000   49.540000  251.200000  4254.000000    0.222600   \n",
       "\n",
       "               27          28          29          30          31  \n",
       "count  569.000000  569.000000  569.000000  569.000000  569.000000  \n",
       "mean     0.254265    0.272188    0.114606    0.290076    0.083946  \n",
       "std      0.157336    0.208624    0.065732    0.061867    0.018061  \n",
       "min      0.027290    0.000000    0.000000    0.156500    0.055040  \n",
       "25%      0.147200    0.114500    0.064930    0.250400    0.071460  \n",
       "50%      0.211900    0.226700    0.099930    0.282200    0.080040  \n",
       "75%      0.339100    0.382900    0.161400    0.317900    0.092080  \n",
       "max      1.058000    1.252000    0.291000    0.663800    0.207500  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "B    357\n",
       "M    212\n",
       "Name: 1, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[1].value_counts() #imbalanced classes-->stratify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     False\n",
       "1     False\n",
       "2     False\n",
       "3     False\n",
       "4     False\n",
       "5     False\n",
       "6     False\n",
       "7     False\n",
       "8     False\n",
       "9     False\n",
       "10    False\n",
       "11    False\n",
       "12    False\n",
       "13    False\n",
       "14    False\n",
       "15    False\n",
       "16    False\n",
       "17    False\n",
       "18    False\n",
       "19    False\n",
       "20    False\n",
       "21    False\n",
       "22    False\n",
       "23    False\n",
       "24    False\n",
       "25    False\n",
       "26    False\n",
       "27    False\n",
       "28    False\n",
       "29    False\n",
       "30    False\n",
       "31    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seed = 101 #random seed for reproducibility\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Split Features & Class (or target) **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(569, 30) (569,)\n"
     ]
    }
   ],
   "source": [
    "X = df.iloc[:,2:].values\n",
    "#categorical to dummy variable\n",
    "y = pd.get_dummies(df.iloc[:,1],drop_first=True).values.ravel()\n",
    "print(X.shape,y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Split Train Test Sets **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 30) (114, 30) (455,) (114,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    stratify=y,random_state=seed)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=uint8), array([285, 170], dtype=int64))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train,return_counts=True) #similar ratio to original class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Scale features **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM: best ML algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of training set: 98.9%\n",
      "Accuracy of test set: 97.4%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "model = SVC(C=10.0, kernel='rbf', gamma=0.01)\n",
    "model.fit(X_train, y_train)\n",
    "accuracy = model.score(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "print('Accuracy of training set: {:0.1f}%'.format(accuracy*100))\n",
    "print('Accuracy of test set: {:0.1f}%'.format(accuracy_score(y_test,y_pred)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline MLP model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import libraries\n",
    "import keras.backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import KFold,GridSearchCV,StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 12)                372       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 485\n",
      "Trainable params: 485\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nMDOzbjlYmJlZt/4/K7+0+9qBkOUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b1339d4080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEWCAYAAACJ0YulAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3XmYXHWd7/H3t7beu9NJd9YOJJAE\nCTsEBFEHVJDN4IIIiqNeFcdnHPWOeoV7R+eRe2fG0XvdUWFG3BUZ1BlUHBiQTWVJWFQgYEJISGft\nJL1vtX3vH7/qTtN0kk53n1R31ef1PP2k69SpU7+TSs6nfusxd0dERAQgVuwCiIjI9KFQEBGRYQoF\nEREZplAQEZFhCgURERmmUBARkWEKBZFxMrPvmNn/Gee+m8zsdZM9jsjhplAQEZFhCgURERmmUJCS\nUmi2+YSZ/dHMes3sW2Y2z8x+bWbdZnaXmTWO2H+1mT1lZh1mdq+ZHTviuVPM7LHC634CVI56r0vM\n7InCa39vZidOsMzvN7MNZrbXzG4zs4WF7WZmXzSzXWbWWTin4wvPXWRmTxfKttXMPj6hvzCRURQK\nUoreApwHrADeAPwa+J9AE+Hf/IcBzGwF8GPgo0AzcDvwCzNLmVkK+Hfg+8Bs4N8Kx6Xw2lOBm4AP\nAHOAG4DbzKziUApqZq8B/gm4HFgAbAZuLjx9PvDqwnnMAt4G7Ck89y3gA+5eBxwP/OZQ3ldkfxQK\nUoq+6u473X0r8ADwsLs/7u6DwM+BUwr7vQ34lbv/l7tngP8LVAGvAM4EksCX3D3j7rcCa0a8x/uB\nG9z9YXfPuft3gcHC6w7FO4Cb3P2xQvmuBc4ysyVABqgDXgaYu69z9+2F12WAlWZW7+7t7v7YIb6v\nyJgUClKKdo74vX+Mx7WF3xcSvpkD4O55YAuwqPDcVn/xipGbR/x+JPCxQtNRh5l1AIsLrzsUo8vQ\nQ6gNLHL33wBfA64HdprZjWZWX9j1LcBFwGYzu8/MzjrE9xUZk0JBytk2wsUdCG34hAv7VmA7sKiw\nbcgRI37fAvyDu88a8VPt7j+eZBlqCM1RWwHc/SvufhpwHKEZ6ROF7Wvc/VJgLqGZ65ZDfF+RMSkU\npJzdAlxsZq81syTwMUIT0O+BB4Es8GEzS5jZm4EzRrz2X4C/MrOXFzqEa8zsYjOrO8Qy/Ah4j5md\nXOiP+EdCc9cmMzu9cPwk0AsMALlCn8c7zKyh0OzVBeQm8fcgMkyhIGXL3Z8FrgK+CuwmdEq/wd3T\n7p4G3gy8G2gn9D/8bMRr1xL6Fb5WeH5DYd9DLcPdwKeAnxJqJ0cDVxSerieETzuhiWkPod8D4J3A\nJjPrAv6qcB4ik2a6yY6IiAxRTUFERIYpFEREZJhCQUREhikURERkWKLYBThUTU1NvmTJkmIXQ0Rk\nRnn00Ud3u3vzwfabcaGwZMkS1q5dW+xiiIjMKGa2+eB7qflIRERGUCiIiMgwhYKIiAyLtE/BzC4A\nvgzEgX9198+Oev6LwLmFh9XAXHefdajvk8lkaG1tZWBgYLJFntYqKytpaWkhmUwWuygiUqIiCwUz\nixOW/D0PaAXWmNlt7v700D7u/t9H7P837Fvn/pC0trZSV1fHkiVLePGilqXD3dmzZw+tra0sXbq0\n2MURkRIVZfPRGcAGd99YWFzsZuDSA+x/JeEuWIdsYGCAOXPmlGwgAJgZc+bMKfnakIgUV5ShsIiw\n5vyQ1sK2lzCzI4Gl7OeWgmZ2tZmtNbO1bW1tY75ZKQfCkHI4RxEprihDYawr2P6WZL0CuNXdx1wT\n3t1vdPdV7r6qufmgcy/GNJDJsaNzgLxWhRUR2a8oQ6GVcBerIS2Eu0yN5Qom2HQ0Xv29XVT2vMBz\nO7vpS2en9NgdHR18/etfP+TXXXTRRXR0dExpWUREJiPKUFgDLDezpWaWIlz4bxu9k5kdAzQS7nQV\nmcZUnlnWy/z8djbu6mFH5wBTdS+J/YVCLnfgm2HdfvvtzJp1yIOtREQiE1kouHsW+BBwB7AOuMXd\nnzKz68xs9YhdrwRu9qjv9lM9BxpaqKOPoxK7aeseoL0vMyWHvuaaa3juuec4+eSTOf300zn33HN5\n+9vfzgknnADAG9/4Rk477TSOO+44brzxxuHXLVmyhN27d7Np0yaOPfZY3v/+93Pcccdx/vnn09/f\nPyVlExE5FDPuzmurVq3y0WsfrVu3jmOPPRaAz/ziKZ7e1rX/A+QykBskR5xBklSlEmN2foy0cmE9\nf/+G4/b7/KZNm7jkkkt48sknuffee7n44ot58sknh4eO7t27l9mzZ9Pf38/pp5/Offfdx5w5c4bX\ncerp6WHZsmWsXbuWk08+mcsvv5zVq1dz1VUvvcPiyHMVERkvM3vU3VcdbL/ym9EcT0I8RZwcMfKk\ns/kpf4szzjjjRXMJvvKVr3DSSSdx5plnsmXLFtavX/+S1yxdupSTTz4ZgNNOO41NmzZNeblERA5m\nxq2SejAH+kY/LJ+HnU/SH6thfWYORzXXUlsxdX8VNTU1w7/fe++93HXXXTz44INUV1dzzjnnjDnX\noKKiYvj3eDyu5iMRKYryqykAxGJQ1UhlrpuqOGxt75/UUNW6ujq6u7vHfK6zs5PGxkaqq6t55pln\neOihhyb8PiIiUSu5msK41czB+nbTUtnP+t4qegay1FdNbE2hOXPmcPbZZ3P88cdTVVXFvHnzhp+7\n4IIL+OY3v8mJJ57IMcccw5lnnjlVZyAiMuVKrqP5kLQ9i3uepzILmV2TYuGsqikqZXTU0SwiE6GO\n5vGonoNlB2hMZugemNoJbSIiM1F5h0JVI1iM2dbNYDYXyUgkEZGZpLxDIRaHyllUZrqIkadnULUF\nESlv5R0KAFWNGHnqY2l6BqZmhrOIyEylUEhVA1CfyNA9mJ2y9ZBERGYihUIsAfEU1ZYml3f6Mwde\nxE5EpJQpFACSVSTzgwD0TGAU0kSXzgb40pe+RF9f34ReKyIy1RQKAMlqLDdITdLonkBns0JBREpF\n+c5oHikZJq3NSmbZ1g+5vBOPjf/WlyOXzj7vvPOYO3cut9xyC4ODg7zpTW/iM5/5DL29vVx++eW0\ntraSy+X41Kc+xc6dO9m2bRvnnnsuTU1N3HPPPVGdoYjIuJReKPz6Gtjxp0N8UR7SvTTGKqjIxfBk\nLKyPNGT+CXDhZ/f76s9+9rM8+eSTPPHEE9x5553ceuutPPLII7g7q1ev5v7776etrY2FCxfyq1/9\nCghrIjU0NPCFL3yBe+65h6ampgmcrIjI1FLzERBuJ20YYfLaZAYg3Xnnndx5552ccsopnHrqqTzz\nzDOsX7+eE044gbvuuotPfvKTPPDAAzQ0NExN0UVEplDp1RQO8I3+gPZsgFyGzZmFzKpJsWiC6yC5\nO9deey0f+MAHXvLco48+yu233861117L+eefz6c//emJlVVEJCKqKQxJVmPZQSoSxuAhDksduXT2\n61//em666SZ6enoA2Lp1K7t27WLbtm1UV1dz1VVX8fGPf5zHHnvsJa8VESm20qspTFSyCnBq41k6\nMof21zJy6ewLL7yQt7/97Zx11lkA1NbW8oMf/IANGzbwiU98glgsRjKZ5Bvf+AYAV199NRdeeCEL\nFixQR7OIFF15L509UnYAdq2jq2IBm/orOX5hA7FDGIF0uGjpbBGZiGmxdLaZXWBmz5rZBjO7Zj/7\nXG5mT5vZU2b2oyjLc0DxCrAYFR4msQ3mtGKqiJSfyJqPzCwOXA+cB7QCa8zsNnd/esQ+y4FrgbPd\nvd3M5kZVnoMyg2Q1ifwA0EA6k6MqGS9acUREiiHKmsIZwAZ33+juaeBm4NJR+7wfuN7d2wHcfddE\n32xKmsGSVcRyAxgwOA3vrTDTmvpEZOaJMhQWAVtGPG4tbBtpBbDCzH5nZg+Z2QVjHcjMrjaztWa2\ntq2t7SXPV1ZWsmfPnslfNJNVmOepjmenXSi4O3v27KGysrLYRRGREhbl6KOxemlHX7UTwHLgHKAF\neMDMjnf3jhe9yP1G4EYIHc2jD9rS0kJraytjBcYhyaWhexddsUEGrZKeuorJHW+KVVZW0tLSUuxi\niEgJizIUWoHFIx63ANvG2Ochd88Az5vZs4SQWHMob5RMJlm6dOlkyhr07YXPvZpfLfwb/m7Hq3n8\n0+dP/pgiIjNIlM1Ha4DlZrbUzFLAFcBto/b5d+BcADNrIjQnbYywTAdW1QjJGo6M76G9L0N7b7po\nRRERKYbIQsHds8CHgDuAdcAt7v6UmV1nZqsLu90B7DGzp4F7gE+4+56oynRQZjBrMXPzob974+7e\nohVFRKQYIp3R7O63A7eP2vbpEb878LeFn+mhYTENHdsBeH53L6cd2VjkAomIHD5a+2i0WYtJ9W4l\nETOe391T7NKIiBxWCoXRGhZj/e2saDQ2tqn5SETKi0JhtFlHAHBaQw/Pq09BRMqMQmG0hjCK9ria\nTp7f3Us+r1nEIlI+FAqjzQqhcFSyncFsnu1dA0UukIjI4aNQGK12PsSSLLLCsNQ2dTaLSPlQKIwW\ni0FDC42ZnQC0tvcXuUAiIoePQmEssxZT2bsNM9jRqeYjESkfCoWxNBxBrHMLTbUVCgURKSsKhbHM\nWgw9O2ipi7NDHc0iUkYUCmMpDEs9trqLnQoFESkjCoWxFIalLq9oZ7uaj0SkjCgUxlKoKRwZ30Nn\nf4aBTK7IBRIROTwUCmOpXwQY8wl3clNns4iUC4XCWBIpqF9IU3YHgJqQRKRsKBT2p2ExdQMhFNTZ\nLCLlQqGwP7MWU9G7FUDDUkWkbCgU9qdhMbHubTRUxNSnICJlQ6GwP7MWQz7LyrpehYKIlA2Fwv40\nhJvtHFvVqeYjESkbCoX9KUxgOzrVro5mESkbkYaCmV1gZs+a2QYzu2aM599tZm1m9kTh531RlueQ\n1C0AYFGik13dg+R0BzYRKQOJqA5sZnHgeuA8oBVYY2a3ufvTo3b9ibt/KKpyTFhFHSRrmEs7ubyz\nu2eQefWVxS6ViEikoqwpnAFscPeN7p4GbgYujfD9ppYZ1M1jdn4PoFnNIlIeogyFRcCWEY9bC9tG\ne4uZ/dHMbjWzxWMdyMyuNrO1Zra2ra0tirKOrW4BdZndgGY1i0h5iDIUbIxtoxvmfwEscfcTgbuA\n7451IHe/0d1Xufuq5ubmKS7mAdTNp3Ig3KtZnc0iUg6iDIVWYOQ3/xZg28gd3H2Puw8WHv4LcFqE\n5Tl0dQuI9ewkGdesZhEpD1GGwhpguZktNbMUcAVw28gdzGzBiIergXURlufQ1c3Hsv0cVZtXn4KI\nlIXIRh+5e9bMPgTcAcSBm9z9KTO7Dljr7rcBHzaz1UAW2Au8O6ryTEhhWOrLansUCiJSFiILBQB3\nvx24fdS2T4/4/Vrg2ijLMCl18wE4urKHPykURKQMaEbzgRRqCkcmO9neOYC7JrCJSGlTKBxI7TwA\nFsQ66M/k6BrIFrlAIiLRUigcSEUtVNTTZB2AhqWKSOlTKBxM3XxmZcMENnU2i0ipUygcTN18atIK\nBREpDwqFg6lbQLJvJwC7uhUKIlLaFAoHUzefWM8OGioT7OoePPj+IiIzmELhYOoWQC7N0bVpdnUp\nFESktCkUDqYwgW15dY+aj0Sk5CkUDqYwgW1pqkvNRyJS8hQKB1OoKbQkQyhoVrOIlDKFwsHUhlCY\nb+2ks3m6+jWrWURKl0LhYJKVUNXIHN8LQFuP+hVEpHQpFMajbgEN2XCvZo1AEpFSplAYj7r5VA+G\ne0Ors1lESplCYTzqFpDq16xmESl9CoXxqJuP9eykKqnmIxEpbQqF8ahbgHmOFbVpNR+JSElTKIxH\nYa7CiqpuNR+JSElTKIzH0Kzmym7VFESkpEUaCmZ2gZk9a2YbzOyaA+x3mZm5ma2KsjwTVqgpLE50\n0KZQEJESFlkomFkcuB64EFgJXGlmK8fYrw74MPBwVGWZtNp5gDHf2ukeyDKQyRW7RCIikYiypnAG\nsMHdN7p7GrgZuHSM/f438Dlg+jbWx5NQN5+mfGGugkYgiUiJijIUFgFbRjxuLWwbZmanAIvd/ZcH\nOpCZXW1ma81sbVtb29SXdDzqF9KQGZrANn3zS0RkMqIMBRtj2/ASo2YWA74IfOxgB3L3G919lbuv\nam5unsIiHoL6hdQM7AI0q1lESleUodAKLB7xuAXYNuJxHXA8cK+ZbQLOBG6btp3N9S0ke7cBzq4u\n1RREpDRFGQprgOVmttTMUsAVwG1DT7p7p7s3ufsSd18CPASsdve1EZZp4uoXEsv0Mis2oJqCiJSs\nyELB3bPAh4A7gHXALe7+lJldZ2aro3rfyDSE7pCV1V0alioiJSsR5cHd/Xbg9lHbPr2ffc+JsiyT\nVh9CYUV1F88rFESkRGlG83jVLwRgabJDzUciUrLGFQpm9hEzq7fgW2b2mJmdH3XhppW6BYDREm+n\nTUNSRaREjbem8N/cvQs4H2gG3gN8NrJSTUfxJNTOYx572dObJpvLF7tEIiJTbryhMDTn4CLg2+7+\nB8aeh1DaGhYxO9eGO+zuSRe7NCIiU268ofComd1JCIU7CusVld9X5fqF1KeHJrCpCUlESs94Rx+9\nFzgZ2OjufWY2m9CEVF7qW6ga+A1hAps6m0Wk9Iy3pnAW8Ky7d5jZVcDfAZ3RFWuaql9IPNNLHf20\n9SgURKT0jDcUvgH0mdlJwP8ANgPfi6xU01VhWOoC28NOLXUhIiVovKGQdXcnLH39ZXf/MmHtovLS\n0ALAy6q72d6hUBCR0jPeUOg2s2uBdwK/KtxAJxldsaapQk1hRVUX2zr7i1wYEZGpN95QeBswSJiv\nsINwX4TPR1aq6aowgW1pqoOtHQoFESk94wqFQhD8EGgws0uAAXcvvz6FwgS2RbG9bOvoJ7SoiYiU\njvEuc3E58AjwVuBy4GEzuyzKgk1b9Qtpzu9mIJOnvS9T7NKIiEyp8c5T+F/A6e6+C8DMmoG7gFuj\nKti01bCIhu6nAdjW0c/smlSRCyQiMnXG26cQGwqEgj2H8NrSUr+IqoGdAOpXEJGSM96awn+a2R3A\njwuP38ao+ySUjfpFxDM91NHHNoWCiJSYcYWCu3/CzN4CnE1YCO9Gd/95pCWbrgrDUo9ItCsURKTk\njPvOa+7+U+CnEZZlZihMYDu+todtmsAmIiXmgKFgZt3AWOMuDXB3r4+kVNNZoaawvKqLX6qmICIl\n5oCh4O7lt5TFwdQtAIuzNLFbzUciUnLKcwTRZMST0LiEI/Jb2dU9yGA2V+wSiYhMmUhDwcwuMLNn\nzWyDmV0zxvN/ZWZ/MrMnzOy3ZrYyyvJMmaYVzE2/AMDOTi2hLSKlI7JQKCyadz1wIbASuHKMi/6P\n3P0Edz8Z+BzwhajKM6WaV1DXu5k4Oc1VEJGSEmVN4Qxgg7tvdPc0cDNh6e1h7t414mENY3dqTz9N\nxxDLZzjCdqlfQURKyriHpE7AImDLiMetwMtH72Rmfw38LZACXjPWgczsauBqgCOOOGLKC3rImo8B\nYJltVSiISEmJsqZgY2x7SU3A3a9396OBTxJu8/nSF7nf6O6r3H1Vc3PzFBdzApqWA3Bi5U7dV0FE\nSkqUodAKLB7xuAXYdoD9bwbeGGF5pk5lA9TOZ2VyB1s1gU1ESkiUobAGWG5mS80sBVwB3DZyBzNb\nPuLhxcD6CMsztZpXcBRqPhKR0hJZn4K7Z83sQ8AdQBy4yd2fMrPrgLXufhvwITN7HZAB2oF3RVWe\nKdd0DAs3r2Vbfx/ujtlYrWUiIjNLlB3NuPvtjFpN1d0/PeL3j0T5/pFqPoaKfB+16T109meYVa37\nKojIzKcZzRPVtAKAZbGtmqsgIiVDoTBRLxqWqs5mESkNCoWJqp1HPlXHMtumzmYRKRkKhYkyw5qP\nYXlsG63tfcUujYjIlFAoTII1H8OK+HY2tvUWuygiIlNCoTAZTSuY43vZtnNnsUsiIjIlFAqTUehs\nruzcQH9a91UQkZlPoTAZhWGpR9s2nmvrKXJhREQmT6EwGbOOJB+vYIW1sn5Xd7FLIyIyaQqFyYgn\nYOGpnBlbx/qdqimIyMynUJik2NHncnzsebZuP9ACsCIiM4NCYbKOOocYTsOOB4tdEhGRSVMoTNai\nUxmM13BM36MMZDQCSURmNoXCZMWTtDefwSvsSU1iE5EZT6EwBezoc1ga20nr888UuygiIpOiUJgC\njcefB0D+uXuLWxARkUlSKEyB1PyV7LZGZu/6fbGLIiIyKQqFqWDGhprTWN77GOTzxS6NiMiEKRSm\nSPv8V9DonaS3P1nsooiITJhCYYrEl50LQPuTdxa5JCIiExdpKJjZBWb2rJltMLNrxnj+b83saTP7\no5ndbWZHRlmeKC0+chnP5BdTse5n4F7s4oiITEhkoWBmceB64EJgJXClma0ctdvjwCp3PxG4Ffhc\nVOWJ2tKmGr6fO59ZHU/B5t8VuzgiUmq6D899W6KsKZwBbHD3je6eBm4GLh25g7vf4+5D97J8CGiJ\nsDyRqkzGeazx9XTHGuD3Xy12cUSklGx9DL62CtZ8K/K3ijIUFgFbRjxuLWzbn/cCv46wPJE79eiF\nfD93Hvz5P6Htz8UujoiUgh1PwvffBFWzYMXrI3+7KEPBxtg2ZmO7mV0FrAI+v5/nrzaztWa2tq2t\nbQqLOLXOXtbEtwZfSz5eAQ9+rdjFEZGZru1Z+N6lkKyGd/0CGqJvTIkyFFqBxSMetwAvWV/azF4H\n/C9gtbsPjnUgd7/R3Ve5+6rm5uZICjsVzjpqDnutgaeaL4Y/3Aw90zfARKRI8nnY+TQ8d8/+5zXl\n8/DkT+G7bwCLhUBoXHJYipeI8NhrgOVmthTYClwBvH3kDmZ2CnADcIG774qwLIdFY02KlQvquSl/\nIV/M/Qwe/ia89lPFLpaIFIM7DHRC5xbY/WfYvR52/Ak2/x7694Z9jngFrP4qNC0Lj3MZ+PMdcM8/\nwq6nYO5KuOymfc8fBpGFgrtnzexDwB1AHLjJ3Z8ys+uAte5+G6G5qBb4NzMDeMHdV0dVpsPh7GVN\nfOd3PXz+xDeR+N2X4dhLYOEpxS6WiETNHV54EB7/Qfizewdk+kbsYDB7KRxzESw5G7KDcNffwzfP\nhlXvhfZN8Pz9kO6G2UfDW74Fx70ZYod3Opn5DBtTv2rVKl+7dm2xi7Ff9z67i3d/ew0/vmoFZ915\nKSQq4AP3Q0VdsYsmIlOtvwNa14QQePo/YM8GSNXBstdAw2Komw/1i6BpBcw5GpJVL3599w741cfg\nmV9CwxHhdcteBysuDLf7nUJm9qi7rzrYflE2H5WlM5bOJhk37tuS46y3/Ct852L45d/Cm28EG6vv\nXURmhIEuaH8etv8xBEHrGti1DnCwOBxxJrzqY7DyUkjVjO+YdfPhbT+A/naoapwW1wiFwhSrTiU4\nZXEjv39uN1z4SjjnWrjnH+Coc+CUdxS7eCIyHns3wpY1sO0x2PZ46A8Y6gcAqGyAltNh5RtDGLSs\nGn8QjGYG1bOnptxTQKEQgVcsm8OX715PZ1+Ghld9DDY9AL/4CNQ0HZZxxiJlKZeB9s3QsSn82bs7\nfPuuaQpj/Ad7QsfvQAcMdoefdA9UzYa6BVA9B7auhfV3hlCAMBR0/onh23/jkvAz91iYs/ywt/Uf\nLgqFCJy9rIkv3bWeBzfu4YLj58Pl3w9jjX/yTrjyx7DstcUuosjMku6Djs3QszMs99DbFr659+2F\n7u3hm3z7JvBDuE96qi608fe3Qz4TtiUqYemr4eUfDJ3BTcdMedv+dFdeZ3uYnNQyi+pUnN8/tzuE\nQtUseOfP4bur4ea3wzv+LfzDEykF+XwYMZOsefEFNJcNF+7OLdCxBbq2QSwOFfWh+aVuXuiMrW56\n6bfunl1hZYDND8L2J6DtGfBRY/otHmoCtfNg3nFw3BthzrLwbX7WkVA7N9QMettCh3BFbXjfyoYQ\nCEPvmc+HYOjdFV47ujO4zCgUIpBKxHjlsiZu/9MOPnXJSpLxWGgz/Mt/h+9cAj94C7z+H+H0902L\njiWRQ/bcPXD3ddC1NTTTDH1Dr2iAyvrQNDPQMb5jxSugYVEYpdPQAnueC524ONQ0w4KT4WUXQ/PL\nQsds7bywvbLh4P9/aprCz4HEYlAzJ/yIQiEqbzt9MXc+vZO71+3kguMXhI01TfCe2+HnfwW3fzys\npvqGr4T/RCIzxZpvwe2fCGPuV7w+XKCrGkObfX87DHaFIdjVc8JP/cJQI2hoKUzo6gjf4Lt3QGcr\ndL4AnVtDwDx/fzjeOdfCyy6Cecfri9NhplCIyF+saGZBQyU/fmTLvlCAUGO48mb4/VfCN62tj8FF\nn1cHtExvuWxoz3/wenjoelh+fphcNZEvNPpGPq0pFCKSiMd466rFfPU369myt4/Fs6v3PRmLwSs/\nCotfDr/4MPzo8jDL8YJ/Omzrm4iMyR3SvWFZhs2/g02/he1/CIEw1Kb/8g/C+f+n7Dpgy4VmNEdo\na0c/r/zn3/A35y7jb88/Zuydsml46Otw3+cgl4bj3wxnflBLY8jkZQfDBX3LI6GNP1Udhljm0qHz\ntbcN+grNPQOdoTO2tw2y/fuOMWdZGI/fsBjqF4R2/SNfUbxzkgkb74xmhULE3v3tR1i3vYvfffI1\nJOIHGNfcuTXcnOfx74ex04tfDiddGUZUVDUevgLL9JIZgC0PwbYnQpv83JXhQm0W/p30t0Pr2tAW\n/8KDkOmHeApiiTCEM5ce+7ixZGi7r55dGA1UD5WzoLY5bG9YDEecFYJASoJCYZq446kdfOD7j/Iv\nf7mK81bOO/gLBjrh8R/C2ptgz/rwH3zZeXD0ubDkVdB8jDreSoF7uKB3toZx9j07w0/v7nCxT/eF\nYZmtayA3ekV54yW3JqmcBUeeDdWNofaZG4RZR4QvFy1nhEEOmf6wQFssMW2WVJDDR6EwTWRyeV7x\n2d/wsvl1fP+9Lx//C93D+Ow/3gJP3wZdrWF7zdywZMbRrwlBUTc/imLLeOXz0LMDuraHce49u6Bv\nTxhh098RLvx9e8N4/cFuyGfDT7p31AqaBam6MJ4+VROGXC5+OSz9C1h8RgiPXetCe38sAanasO+C\nk8IonVj88J+/zBgKhWnkhvspghVlAAARwElEQVSe459+/Qzfec/pnHPM3EM/gHtYiGvTb2HjfbDx\nXujbHZ6rmg2zjworMC48FY54Ocw7QZ2AU8k9zJjddH+YNduza8Rwyi1jN9HEU+Hb+9AyC9WzwwU/\nnggX9ETVvrH59YvCRK6auZCsPOynJ+VBoTCNDGZzXPClBzDgPz/6alKJSa6Zks/Dzj+FkNi9PqzT\nsns9dBdubJesDhekWDz8NCwObdHzVoaL0WBX+CYbr9g3GWjW4jAL9HB+28xlw1oz2cEwrr2yYd9s\n10TqMJYjE5rtenaGi33PznDh79kV/k5feCh8S4fC39m88HdWvwgajwzNNPWLwgzamrlhbH6ySs0z\nMq1o6exppCIR59NvWMl7vr2G7/z+ea5+9dGTO2AsFpoMFpz04u2dreEC1ro2LDuQz4c1XfY+H278\nkek98HHjqXBzj/oF4eKXSIWlBDwfZqzGU2EiUn1LuDCmasPFL1EZ9snnwp9m4RaCEL5F59LhwouF\n0MmlYcNdsO4XYbTLWBJV4djxVChHsjo0qaRqwjbPF35GfKnJZQqB1wXZgfD6ZHW4p0U+G57PZ/aV\nM5cJTTr7+3tJ1oQL/RFnhiaco/4CGpfqYi8lTTWFw+i931nDQxv3cM/Hz2Fu/WFuJsjnw8zRfK7w\njbwuXDi7d4Y28fbN+24Z2LsrXLiz6RAGFg8X+exAWL/mJR2fE5CsDhP2Vl4aRrsMdoeL+VAtZqAz\ndIwOlSPTF9rh071hW6xQJkZcoGOJMIqmoj4EQXYgvC6bDs/FE2HUTSwezikW37cWTmVDKEfdghAE\ntfNCe71IiVDz0TS0aXcv53/xfi46YT5fumKGzkNwDyNkenbuG82SHQwX6FhsXw1h6Ft8PBUu0LEE\n4IUblXtYwGyi68+LyCFT89E0tKSphg+eczRfvns9Zx09h7edfkSxi3TozMJY9trmYpdERCJQmneJ\nmMY+/NrlvHJZE5/6j6f4w5ZxriIpInKYKBQOs3jM+OqVp9BcW8EHf/Aou3umoH1eRGSKRBoKZnaB\nmT1rZhvM7Joxnn+1mT1mZlkzuyzKskwnjTUpbnjnaezpTfPXP3yMgcwh3C1KRCRCkYWCmcWB64EL\ngZXAlWa2ctRuLwDvBn4UVTmmq+MXNfC5y07kkU17ed9319KfVjCISPFFWVM4A9jg7hvdPQ3cDFw6\ncgd33+TufwTyYx2g1F168iI+f9lJ/O653bzve2sUDCJSdFGGwiJgy4jHrYVth8zMrjaztWa2tq1t\nP5OdZqjLTmvh85edxO+f28N7vvMI7b37WdVSROQwiDIUxpr2OaFJEe5+o7uvcvdVzc2lNxTystNa\n+MLlJ/HY5g4u+soDPLp5b7GLJCJlKspQaAUWj3jcAmyL8P1mtDed0sJPP/gKEnHjbTc8xDfve45s\nrixb1USkiKIMhTXAcjNbamYp4Argtgjfb8Y7oaWBX/7Nqzhv5Tw+++tnuPDLD3Dvs7uKXSwRKSOR\nhYK7Z4EPAXcA64Bb3P0pM7vOzFYDmNnpZtYKvBW4wcyeiqo8M0VDVZKvv+NUbnjnaWRyed797TW8\n81sP8/gL7cUumoiUAa19NI2ls3m+/9Bmvvqb9XT0ZXjV8iY+/NrlnL5kdrGLJiIzjBbEKyE9g1l+\n8NBm/uX+jezpTXNiSwNXnXkkq09aSGVSd9sSkYNTKJSg/nSOWx/dwvce3Mz6XT00VCU5b+U8zl85\nj1ctb6YqpYAQkbEpFEqYu/Pw83v5yZot3LVuJ90DWSqTMc48ag6vWt7Mq5c3sWxuLaabwYhIgZbO\nLmFmxplHzeHMo+aQyeV5eONe/uvpHTywfjf/+9mnAWiqreDlS2dzxtLZnHZkI8fMryMZ1/qHInJg\nCoUZLhmP8crlTbxyeRMAre19/Hb9bh5+fi8Pb9zDr/4U7i1ckYhx/KIGjl9Yz8sW1HPM/DqWz62l\nrjJZzOKLyDSj5qMSt2VvH09s6Rj+eWZ7F70j1lhqqk1x5JwaljXXcuyCOo5dUM+KeXXMqk6q+Umk\nhKhPQcaUzztbO/pZt72Ljbt72bS7l+d397J+Vw97R6y7VFeRoGV2NS2NVSxoqGR+QyULG6poaayi\npbGauXUVxGIKDZGZQn0KMqZYzFg8u5rFs6tftN3d2dk1yLrtXTzX1sOWvX28sLePzXt6eXjjHroG\nsi/aPxk35taFsJhfX0lzXUX4qa1gdk2KObUp5tRUMLs2RU0qrlqHyAyhUBAgdF7PL9QIzn3Z3Jc8\n35fOsq1jgNb2Pra097O1vZ+dXQNs7+zn6e1d7P7zIN2D2TGOHPoz5tSkaKxJMbsmRWN1ivqqBHWV\nSWorEiFEalI01VXQWJ2ioSpJfWWChDrGRQ47hYKMS3UqwbK5tSybW7vffQYyOdq6B9nbm2Zvb5rd\nPeH3Pb1p9vSkae8L21/Y20f3QJbugQyZ3P6bL2tS8RAQVUlmVSeZUxtqIvVVSSoSMSqTcSqTMWpS\nCapScWpSCeoqh36S1FUmqEjEVEsROQQKBZkylcn4mE1T++PuDGbzITh6Qoh09Kfp7MvQ2Z+layBD\nZ3/46ehL8/S2LnZ3779GMpZk3KitSFCdSlBbkaCmIk59VbJQG0lSX5Uo/BlCpLZiX6AMhYuav6Sc\nKBSkaMyMymSchbOqWDiratyvy+eddC7PYCZPfyZHXzpLXzpH72A21EAGM3QPZOkZzNIzELb1prP0\nDoZte3vTbNrdS2d/hq6BLLn8gQdbpBIxmmsraKqroLYiTkUiTioeoyoVpzIZpyoZpzoVp7YyQU1F\ngppU2FaZjFORiJFMxEjEjIpEnJqKONWpBNWF18bVWS/TjEJBZpxYzKiMhYtqA5ObZ+Hu9KVzdPZn\n6BkMTVpdA/vCpHsgw97eNG3dg7T1DNKXztHVn2Ugk2MwG0KpPx2C6SDZMqZUPEZFMjYcIBWJGNWp\nRAiVVJxkzEjEjUQ8RjJmJOMhZOorkzRWJ2msTlGRDK9LFZrUhkJnaFsqvi+YErEYybip5iP7pVCQ\nsmZm4dt9xeT+K7g7/ZkcPYNZ+tO54bAYzObJ5pxMLs9gNhdqNOkcfYNZBjJ5BrL79hvM5hgovK4/\nE4Iqmyu8Ph/+zObypHN5OvsP3B9zIDGDmlQ45+pUPARHIkZlIk5VoZZTlYoXwiTUcIa2DdWKqitC\ncCViRjxmJGI2HEoh3OIh7BJxKlMhmBREM4NCQWQKmFnhG/rh+S/l7vSmc7T3phnMhlBJZ/MMZPLD\nzWmD2TyZXNieyeXJ5kOoDGTy9Axmh/dLZ0PQDGRydPSl2ZbOMZDNkckONdPl6MvkmMyUppiFwQrJ\nEbWeeDzUXOIxK9SQ4lSlElSOqOFUJIf+jA8PLqhKxoe3pxIxkvF9taGhbRWF7WbhvsDh8wmDEaor\nQpgppMamUBCZgcxCB3rtJGs44zU0KKA/HQKiP52lP50nm8+TdyeTc9LZPIPZ/HDTWqj5hMcDmVBL\nyuTyZAo1p3zeyeadXN4ZzOboHQy1o12Z3PCx0oVQS2dDrWoq59qm4qEprbLQ/1OZDEGSjMdIxENT\n3VCTXkWiUANKxknGjZgVakhxo6IQWkOBNBRKqREhNTKoErFw/KHmvNA8aMPvkYrHijoxVKEgIgc1\nNCigMhmnsUhlcA81l4F0CIihGlB6RG1oqMYUHjtOSJFc3ukf0XQXXrevWa8/HcIrncuHJrt8CLme\nwSx7evbVpAYyIQhzeSefdzKF/aZaaiiQCjWiRCHAPvK6Faw+aeGUv99ICgURmRHMhr5NT36AwVQa\nCquhMBoOptxLH2eyhWa8oT6ivJPL519S0xoaXTeQzZEt1K7SuTyzqqI/b4WCiMgkjAyrUqB1BERE\nZFikoWBmF5jZs2a2wcyuGeP5CjP7SeH5h81sSZTlERGRA4ssFMwsDlwPXAisBK40s5Wjdnsv0O7u\ny4AvAv8cVXlEROTgoqwpnAFscPeN7p4GbgYuHbXPpcB3C7/fCrzWNHhYRKRoogyFRcCWEY9bC9vG\n3Mfds0AnMCfCMomIyAFEGQpjfeMfPfVkPPtgZleb2VozW9vW1jYlhRMRkZeKMhRagcUjHrcA2/a3\nj5klgAZg7+gDufuN7r7K3Vc1NzdHVFwREYkyFNYAy81sqZmlgCuA20btcxvwrsLvlwG/8Zl202gR\nkRJiUV6Dzewi4EtAHLjJ3f/BzK4D1rr7bWZWCXwfOIVQQ7jC3Tce5JhtwOYJFqkJ2D3B185k5Xje\n5XjOUJ7nXY7nDId+3ke6+0GbWiINhenGzNa6+6pil+NwK8fzLsdzhvI873I8Z4juvDWjWUREhikU\nRERkWLmFwo3FLkCRlON5l+M5Q3medzmeM0R03mXVpyAiIgdWbjUFERE5AIWCiIgMK5tQONgy3qXA\nzBab2T1mts7MnjKzjxS2zzaz/zKz9YU/i3VHxciYWdzMHjezXxYeLy0sx76+sDx7qthlnGpmNsvM\nbjWzZwqf+Vll8ln/98K/7yfN7MdmVllqn7eZ3WRmu8zsyRHbxvxsLfhK4dr2RzM7dTLvXRahMM5l\nvEtBFviYux8LnAn8deE8rwHudvflwN2Fx6XmI8C6EY//Gfhi4ZzbCcu0l5ovA//p7i8DTiKcf0l/\n1ma2CPgwsMrdjydMjL2C0vu8vwNcMGrb/j7bC4HlhZ+rgW9M5o3LIhQY3zLeM567b3f3xwq/dxMu\nEot48RLl3wXeWJwSRsPMWoCLgX8tPDbgNYTl2KE0z7keeDXwLQB3T7t7ByX+WRckgKrCemnVwHZK\n7PN29/t56Tpw+/tsLwW+58FDwCwzWzDR9y6XUBjPMt4lpXAXu1OAh4F57r4dQnAAc4tXskh8Cfgf\nQL7weA7QUViOHUrz8z4KaAO+XWg2+1czq6HEP2t33wr8X+AFQhh0Ao9S+p837P+zndLrW7mEwriW\n6C4VZlYL/BT4qLt3Fbs8UTKzS4Bd7v7oyM1j7Fpqn3cCOBX4hrufAvRSYk1FYym0o18KLAUWAjWE\n5pPRSu3zPpAp/fdeLqEwnmW8S4KZJQmB8EN3/1lh886h6mThz13FKl8EzgZWm9kmQrPgawg1h1mF\n5gUozc+7FWh194cLj28lhEQpf9YArwOed/c2d88APwNeQel/3rD/z3ZKr2/lEgrjWcZ7xiu0pX8L\nWOfuXxjx1Mglyt8F/MfhLltU3P1ad29x9yWEz/U37v4O4B7CcuxQYucM4O47gC1mdkxh02uBpynh\nz7rgBeBMM6su/HsfOu+S/rwL9vfZ3gb8ZWEU0plA51Az00SUzYzmsZbxLnKRppyZvRJ4APgT+9rX\n/yehX+EW4AjCf6q3uvtLbmY005nZOcDH3f0SMzuKUHOYDTwOXOXug8Us31Qzs5MJnespYCPwHsIX\nvZL+rM3sM8DbCKPtHgfeR2hDL5nP28x+DJxDWB57J/D3wL8zxmdbCMevEUYr9QHvcfe1E37vcgkF\nERE5uHJpPhIRkXFQKIiIyDCFgoiIDFMoiIjIMIWCiIgMUyiIHEZmds7QSq4i05FCQUREhikURMZg\nZleZ2SNm9oSZ3VC4X0OPmf0/M3vMzO42s+bCvieb2UOFtex/PmKd+2VmdpeZ/aHwmqMLh68dcR+E\nHxYmH4lMCwoFkVHM7FjCjNmz3f1kIAe8g7D42mPufipwH2GWKcD3gE+6+4mE2eRD238IXO/uJxHW\n5xlaeuAU4KOEe3scRVi/SWRaSBx8F5Gy81rgNGBN4Ut8FWHxsTzwk8I+PwB+ZmYNwCx3v6+w/bvA\nv5lZHbDI3X8O4O4DAIXjPeLurYXHTwBLgN9Gf1oiB6dQEHkpA77r7te+aKPZp0btd6A1Yg7UJDRy\nTZ4c+n8o04iaj0Re6m7gMjObC8P3xj2S8P9laCXOtwO/dfdOoN3MXlXY/k7gvsJ9LFrN7I2FY1SY\nWfVhPQuRCdA3FJFR3P1pM/s74E4ziwEZ4K8JN7I5zsweJdzx622Fl7wL+Gbhoj+0WimEgLjBzK4r\nHOOth/E0RCZEq6SKjJOZ9bh7bbHLIRIlNR+JiMgw1RRERGSYagoiIjJMoSAiIsMUCiIiMkyhICIi\nwxQKIiIy7P8DMcxeLAkH2VcAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b1342fdb70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss of train set: 0.022\n",
      "accuracy of train set: 99.3%\n",
      "loss of test set: 0.203\n",
      "accuracy of test set: 94.7%\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "np.random.seed(seed) \n",
    "\n",
    "# train model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, kernel_initializer='uniform', input_shape=(X_train.shape[1],), activation='relu'))\n",
    "model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
    "model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.summary()\n",
    "history = model.fit(X_train, y_train,validation_data=(X_test,y_test), \n",
    "                    epochs=100, verbose=0)\n",
    "\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "# evaluate model on train set\n",
    "scores = model.evaluate(X_train,y_train,verbose=0)\n",
    "print('loss of train set: {:0.3f}'.format(scores[0]))\n",
    "print('accuracy of train set: {:0.1f}%'.format(scores[1]*100))\n",
    "# evaluate model on test data\n",
    "scores = model.evaluate(X_test,y_test,verbose=0)\n",
    "print('loss of test set: {:0.3f}'.format(scores[0]))\n",
    "print('accuracy of test set: {:0.1f}%'.format(scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Tuning\n",
    "try to improve model to deafeat the accuracy SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch & epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 8 candidates, totalling 24 fits\n",
      "152/152 [==============================] - 0s 233us/step\n",
      "303/303 [==============================] - 0s 50us/step\n",
      "152/152 [==============================] - 0s 256us/step\n",
      "303/303 [==============================] - 0s 49us/step\n",
      "151/151 [==============================] - 0s 290us/step\n",
      "304/304 [==============================] - 0s 53us/step\n",
      "152/152 [==============================] - 0s 381us/step\n",
      "303/303 [==============================] - 0s 53us/step\n",
      "152/152 [==============================] - 0s 474us/step\n",
      "303/303 [==============================] - 0s 53us/step\n",
      "151/151 [==============================] - 0s 610us/step\n",
      "304/304 [==============================] - 0s 53us/step\n",
      "152/152 [==============================] - 0s 659us/step\n",
      "303/303 [==============================] - 0s 56us/step\n",
      "152/152 [==============================] - 0s 697us/step\n",
      "303/303 [==============================] - 0s 53us/step\n",
      "151/151 [==============================] - 0s 749us/step\n",
      "304/304 [==============================] - 0s 53us/step\n",
      "152/152 [==============================] - 0s 818us/step\n",
      "303/303 [==============================] - 0s 53us/step\n",
      "152/152 [==============================] - 0s 941us/step\n",
      "303/303 [==============================] - 0s 56us/step\n",
      "151/151 [==============================] - 0s 1ms/step\n",
      "304/304 [==============================] - 0s 59us/step\n",
      "152/152 [==============================] - 0s 1ms/step\n",
      "303/303 [==============================] - 0s 36us/step\n",
      "152/152 [==============================] - 0s 1ms/step\n",
      "303/303 [==============================] - 0s 40us/step\n",
      "151/151 [==============================] - 0s 1ms/step\n",
      "304/304 [==============================] - 0s 33us/step\n",
      "152/152 [==============================] - 0s 1ms/step\n",
      "303/303 [==============================] - 0s 40us/step\n",
      "152/152 [==============================] - 0s 1ms/step\n",
      "303/303 [==============================] - 0s 36us/step\n",
      "151/151 [==============================] - 0s 1ms/step\n",
      "304/304 [==============================] - 0s 40us/step\n",
      "152/152 [==============================] - 0s 2ms/step\n",
      "303/303 [==============================] - 0s 36us/step\n",
      "152/152 [==============================] - 0s 2ms/step\n",
      "303/303 [==============================] - 0s 36us/step\n",
      "151/151 [==============================] - 0s 2ms/step\n",
      "304/304 [==============================] - 0s 33us/step\n",
      "152/152 [==============================] - 0s 2ms/step\n",
      "303/303 [==============================] - 0s 36us/step\n",
      "152/152 [==============================] - 0s 2ms/step\n",
      "303/303 [==============================] - 0s 40us/step\n",
      "151/151 [==============================] - 0s 2ms/step\n",
      "304/304 [==============================] - 0s 39us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  24 out of  24 | elapsed:   51.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.978022 (0.013526) with: {'batch_size': 16, 'epochs': 30}\n",
      "0.978022 (0.013526) with: {'batch_size': 16, 'epochs': 50}\n",
      "0.978022 (0.008202) with: {'batch_size': 16, 'epochs': 70}\n",
      "0.971429 (0.008158) with: {'batch_size': 16, 'epochs': 90}\n",
      "0.978022 (0.012392) with: {'batch_size': 32, 'epochs': 30}\n",
      "0.973626 (0.019372) with: {'batch_size': 32, 'epochs': 50}\n",
      "0.975824 (0.016416) with: {'batch_size': 32, 'epochs': 70}\n",
      "0.975824 (0.003036) with: {'batch_size': 32, 'epochs': 90}\n",
      "\n",
      "\n",
      "Best: 97.8% using {'batch_size': 16, 'epochs': 30}\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "np.random.seed(seed) \n",
    "kfold = StratifiedKFold(n_splits=3, random_state=seed)\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, kernel_initializer='uniform', input_shape=(X_train.shape[1],), activation='relu'))\n",
    "    model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    return model\n",
    "classifier = KerasClassifier(build_fn=create_model)\n",
    "\n",
    "# Grid Search\n",
    "batch_size = [16,32]\n",
    "epochs = [30,50,70,90]\n",
    "param_grid = dict(batch_size=batch_size,epochs=epochs)\n",
    "grid = GridSearchCV(classifier, param_grid=param_grid, cv=kfold, verbose=1) #n_jobs=-1,\n",
    "grid_result = grid.fit(X_train,y_train,verbose=0)\n",
    "\n",
    "# Results\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param)) \n",
    "print(\"Best: {:.1f}% using {}\" .format(grid_result.best_score_*100, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "152/152 [==============================] - 0s 198us/step\n",
      "303/303 [==============================] - 0s 56us/step\n",
      "152/152 [==============================] - 0s 284us/step\n",
      "303/303 [==============================] - 0s 53us/step\n",
      "151/151 [==============================] - 0s 251us/step\n",
      "304/304 [==============================] - 0s 49us/step\n",
      "152/152 [==============================] - 0s 304us/step\n",
      "303/303 [==============================] - 0s 50us/step\n",
      "152/152 [==============================] - 0s 632us/step\n",
      "303/303 [==============================] - 0s 66us/step\n",
      "151/151 [==============================] - 0s 452us/step\n",
      "304/304 [==============================] - 0s 53us/step\n",
      "152/152 [==============================] - 0s 592us/step\n",
      "303/303 [==============================] - 0s 50us/step\n",
      "152/152 [==============================] - 0s 608us/step\n",
      "303/303 [==============================] - 0s 50us/step\n",
      "151/151 [==============================] - 0s 748us/step\n",
      "304/304 [==============================] - 0s 53us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   9 out of   9 | elapsed:   13.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.626374 (0.001949) with: {'optimizer': 'sgd'}\n",
      "0.978022 (0.017267) with: {'optimizer': 'rmsprop'}\n",
      "0.978022 (0.013526) with: {'optimizer': 'adam'}\n",
      "\n",
      "\n",
      "Best: 97.8% using {'optimizer': 'rmsprop'}\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "np.random.seed(seed)\n",
    "kfold = StratifiedKFold(n_splits=3, random_state=seed)\n",
    "def create_model(optimizer='adam'):     \n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, kernel_initializer='uniform', input_shape=(X_train.shape[1],), activation='relu'))\n",
    "    model.add(Dense(8, kernel_initializer='uniform', activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    return model\n",
    "batch_size=16\n",
    "epochs=30\n",
    "classifier = KerasClassifier(build_fn=create_model, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "# Grid Search\n",
    "optimizer = ['sgd', 'rmsprop', 'adam']#, 'Adagrad', 'Adadelta', 'Adamax', 'Nadam']\n",
    "param_grid = dict(optimizer=optimizer)\n",
    "grid = GridSearchCV(classifier, param_grid=param_grid, cv=kfold,verbose=1)\n",
    "grid_result = grid.fit(X_train,y_train,verbose=0)\n",
    "\n",
    "# Results\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))   \n",
    "print(\"Best: {:.1f}% using {}\" .format(grid_result.best_score_*100, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 0s 143us/step\n",
      "303/303 [==============================] - 0s 46us/step\n",
      "152/152 [==============================] - 0s 244us/step\n",
      "303/303 [==============================] - 0s 50us/step\n",
      "151/151 [==============================] - 0s 329us/step\n",
      "304/304 [==============================] - 0s 56us/step\n",
      "152/152 [==============================] - 0s 500us/step\n",
      "303/303 [==============================] - 0s 63us/step\n",
      "152/152 [==============================] - 0s 484us/step\n",
      "303/303 [==============================] - 0s 53us/step\n",
      "151/151 [==============================] - 0s 554us/step\n",
      "304/304 [==============================] - 0s 53us/step\n",
      "152/152 [==============================] - 0s 583us/step\n",
      "303/303 [==============================] - 0s 53us/step\n",
      "152/152 [==============================] - 0s 599us/step\n",
      "303/303 [==============================] - 0s 50us/step\n",
      "151/151 [==============================] - 0s 954us/step\n",
      "304/304 [==============================] - 0s 63us/step\n",
      "0.975824 (0.016416) with: {'init_mode': 'uniform'}\n",
      "0.975824 (0.011176) with: {'init_mode': 'glorot_normal'}\n",
      "0.626374 (0.001949) with: {'init_mode': 'zero'}\n",
      "\n",
      "\n",
      "Best: 97.6% using {'init_mode': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "np.random.seed(seed) #random seed for reproducibility\n",
    "kfold = StratifiedKFold(n_splits=3, random_state=seed)\n",
    "def create_model(init_mode='uniform',optimizer='rmsprop'):     \n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, kernel_initializer=init_mode, input_shape=(X_train.shape[1],), activation='relu'))\n",
    "    model.add(Dense(8, kernel_initializer=init_mode, activation='relu'))\n",
    "    model.add(Dense(1, kernel_initializer=init_mode, activation='sigmoid'))\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    return model\n",
    "batch_size=16\n",
    "epochs=30\n",
    "classifier = KerasClassifier(build_fn=create_model, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "# Grid Search\n",
    "init_mode = ['uniform', 'glorot_normal','zero']#,'lecun_uniform', 'normal',   'glorot_uniform', 'he_normal', 'he_uniform']\n",
    "param_grid = dict(init_mode=init_mode)\n",
    "grid = GridSearchCV(classifier, param_grid=param_grid, cv=kfold,verbose=0) #n_jobs=-1,\n",
    "grid_result = grid.fit(X_train,y_train,verbose=0)\n",
    "\n",
    "# Results\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))    \n",
    "print(\"Best: {:.1f}% using {}\" .format(grid_result.best_score_*100, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 0s 151us/step\n",
      "303/303 [==============================] - 0s 50us/step\n",
      "152/152 [==============================] - 0s 288us/step\n",
      "303/303 [==============================] - 0s 46us/step\n",
      "151/151 [==============================] - 0s 308us/step\n",
      "304/304 [==============================] - 0s 46us/step\n",
      "152/152 [==============================] - 0s 500us/step\n",
      "303/303 [==============================] - 0s 56us/step\n",
      "152/152 [==============================] - 0s 451us/step\n",
      "303/303 [==============================] - 0s 50us/step\n",
      "151/151 [==============================] - 0s 721us/step\n",
      "304/304 [==============================] - 0s 59us/step\n",
      "152/152 [==============================] - 0s 781us/step\n",
      "303/303 [==============================] - 0s 59us/step\n",
      "152/152 [==============================] - 0s 653us/step\n",
      "303/303 [==============================] - 0s 53us/step\n",
      "151/151 [==============================] - 0s 754us/step\n",
      "304/304 [==============================] - 0s 53us/step\n",
      "152/152 [==============================] - 0s 737us/step\n",
      "303/303 [==============================] - 0s 53us/step\n",
      "152/152 [==============================] - 0s 807us/step\n",
      "303/303 [==============================] - 0s 46us/step\n",
      "151/151 [==============================] - 0s 989us/step\n",
      "304/304 [==============================] - 0s 53us/step\n",
      "0.975824 (0.016416) with: {'activation': 'relu'}\n",
      "0.982418 (0.015505) with: {'activation': 'tanh'}\n",
      "0.736264 (0.154189) with: {'activation': 'sigmoid'}\n",
      "0.978022 (0.008202) with: {'activation': 'linear'}\n",
      "\n",
      "\n",
      "Best: 98.2% using {'activation': 'tanh'}\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "np.random.seed(seed) \n",
    "kfold = StratifiedKFold(n_splits=3, random_state=seed)\n",
    "def create_model(activation='relu',init_mode='uniform',optimizer='rmsprop'):     \n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, kernel_initializer=init_mode, input_shape=(X_train.shape[1],), activation=activation))\n",
    "    model.add(Dense(8, kernel_initializer=init_mode, activation=activation))\n",
    "    model.add(Dense(1, kernel_initializer=init_mode, activation='sigmoid'))\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    return model\n",
    "batch_size=16\n",
    "epochs=30\n",
    "classifier = KerasClassifier(build_fn=create_model, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "\n",
    "# Grid Search\n",
    "activation = ['relu', 'tanh', 'sigmoid','linear']#'softmax', 'softplus', 'softsign',  'hard_sigmoid', ]\n",
    "param_grid = dict(activation=activation)\n",
    "grid = GridSearchCV(classifier, param_grid=param_grid, cv=kfold,verbose=0) #n_jobs=-1,\n",
    "grid_result = grid.fit(X_train,y_train,verbose=0)\n",
    "\n",
    "# Results\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "print('\\n')    \n",
    "print(\"Best: {:.1f}% using {}\" .format(grid_result.best_score_*100, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152/152 [==============================] - 0s 237us/step\n",
      "303/303 [==============================] - 0s 53us/step\n",
      "152/152 [==============================] - 0s 221us/step\n",
      "303/303 [==============================] - 0s 46us/step\n",
      "151/151 [==============================] - 0s 285us/step\n",
      "304/304 [==============================] - 0s 46us/step\n",
      "152/152 [==============================] - 0s 375us/step\n",
      "303/303 [==============================] - 0s 53us/step\n",
      "152/152 [==============================] - 0s 444us/step\n",
      "303/303 [==============================] - 0s 53us/step\n",
      "151/151 [==============================] - 0s 683us/step\n",
      "304/304 [==============================] - 0s 59us/step\n",
      "152/152 [==============================] - 0s 625us/step\n",
      "303/303 [==============================] - 0s 66us/step\n",
      "152/152 [==============================] - 0s 659us/step\n",
      "303/303 [==============================] - 0s 53us/step\n",
      "151/151 [==============================] - 0s 726us/step\n",
      "304/304 [==============================] - 0s 49us/step\n",
      "152/152 [==============================] - 0s 785us/step\n",
      "303/303 [==============================] - 0s 56us/step\n",
      "152/152 [==============================] - 0s 908us/step\n",
      "303/303 [==============================] - 0s 59us/step\n",
      "151/151 [==============================] - 0s 1ms/step\n",
      "304/304 [==============================] - 0s 56us/step\n",
      "152/152 [==============================] - 0s 1ms/step\n",
      "303/303 [==============================] - 0s 56us/step\n",
      "152/152 [==============================] - 0s 1ms/step\n",
      "303/303 [==============================] - 0s 56us/step\n",
      "151/151 [==============================] - 0s 1ms/step\n",
      "304/304 [==============================] - 0s 56us/step\n",
      "152/152 [==============================] - 0s 1ms/step\n",
      "303/303 [==============================] - 0s 56us/step\n",
      "152/152 [==============================] - 0s 1ms/step\n",
      "303/303 [==============================] - 0s 53us/step\n",
      "151/151 [==============================] - 0s 2ms/step\n",
      "304/304 [==============================] - 0s 69us/step\n",
      "152/152 [==============================] - 0s 2ms/step\n",
      "303/303 [==============================] - 0s 63us/step\n",
      "152/152 [==============================] - 0s 2ms/step\n",
      "303/303 [==============================] - 0s 59us/step\n",
      "151/151 [==============================] - 0s 2ms/step\n",
      "304/304 [==============================] - 0s 56us/step\n",
      "152/152 [==============================] - 0s 2ms/step\n",
      "303/303 [==============================] - 0s 63us/step\n",
      "152/152 [==============================] - 0s 2ms/step\n",
      "303/303 [==============================] - 0s 59us/step\n",
      "151/151 [==============================] - 0s 2ms/step\n",
      "304/304 [==============================] - 0s 59us/step\n",
      "152/152 [==============================] - 0s 2ms/step\n",
      "303/303 [==============================] - 0s 66us/step\n",
      "152/152 [==============================] - 0s 2ms/step\n",
      "303/303 [==============================] - 0s 63us/step\n",
      "151/151 [==============================] - 0s 2ms/step\n",
      "304/304 [==============================] - 0s 59us/step\n",
      "0.982418 (0.015505) with: {'dropout_rate': 0.0, 'weight_constraint': 3}\n",
      "0.982418 (0.015505) with: {'dropout_rate': 0.0, 'weight_constraint': 4}\n",
      "0.982418 (0.015505) with: {'dropout_rate': 0.0, 'weight_constraint': 5}\n",
      "0.978022 (0.013526) with: {'dropout_rate': 0.2, 'weight_constraint': 3}\n",
      "0.980220 (0.014211) with: {'dropout_rate': 0.2, 'weight_constraint': 4}\n",
      "0.982418 (0.015505) with: {'dropout_rate': 0.2, 'weight_constraint': 5}\n",
      "0.982418 (0.015505) with: {'dropout_rate': 0.3, 'weight_constraint': 3}\n",
      "0.980220 (0.014211) with: {'dropout_rate': 0.3, 'weight_constraint': 4}\n",
      "0.982418 (0.015505) with: {'dropout_rate': 0.3, 'weight_constraint': 5}\n",
      "\n",
      "\n",
      "Best: 98.2% using {'dropout_rate': 0.0, 'weight_constraint': 3}\n"
     ]
    }
   ],
   "source": [
    "from keras.constraints import maxnorm\n",
    "K.clear_session()\n",
    "np.random.seed(seed) \n",
    "kfold = StratifiedKFold(n_splits=3, random_state=seed)\n",
    "def create_model(dropout_rate=0.0, weight_constraint=0,activation='tanh',\n",
    "                 init_mode='uniform',optimizer='rmsprop'):     \n",
    "    model = Sequential()\n",
    "    model.add(Dense(12, kernel_initializer=init_mode, input_shape=(X_train.shape[1],), activation=activation,\n",
    "                   kernel_constraint=maxnorm(weight_constraint)))\n",
    "    model.add(Dense(8, kernel_initializer=init_mode, activation=activation,\n",
    "                   kernel_constraint=maxnorm(weight_constraint)))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1, kernel_initializer=init_mode, activation='sigmoid'))\n",
    "    model.compile(optimizer=optimizer, loss='binary_crossentropy',metrics=['accuracy'])\n",
    "    return model\n",
    "batch_size=16\n",
    "epochs=30\n",
    "classifier = KerasClassifier(build_fn=create_model, epochs=epochs, batch_size=batch_size)\n",
    "\n",
    "# Grid Search\n",
    "weight_constraint = [3,4,5]\n",
    "dropout_rate = [0.0, 0.2,0.3]\n",
    "param_grid = dict(dropout_rate=dropout_rate, weight_constraint=weight_constraint)\n",
    "grid = GridSearchCV(classifier, param_grid=param_grid, cv=kfold, verbose=0) #n_jobs=-1,\n",
    "grid_result = grid.fit(X_train,y_train,verbose=0)\n",
    "\n",
    "# Results\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "print('\\n')    \n",
    "print(\"Best: {:.1f}% using {}\" .format(grid_result.best_score_*100, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model \n",
    "#### param: epochs=30, batch_size=16, optimizer='rmsprop',kernel_initializer='uniform', activation='tanh'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss of train set: 0.042\n",
      "accuracy of train set: 99.3%\n"
     ]
    }
   ],
   "source": [
    "K.clear_session()\n",
    "np.random.seed(seed)\n",
    "# train model\n",
    "model = Sequential()\n",
    "model.add(Dense(12, kernel_initializer='uniform', input_shape=(X_train.shape[1],), \n",
    "                activation='tanh'))\n",
    "model.add(Dense(8, kernel_initializer='uniform', activation='tanh'))\n",
    "model.add(Dense(1, kernel_initializer='uniform', activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy',metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=30, batch_size=16, verbose=0)\n",
    "# evaluate model on train set\n",
    "scores = model.evaluate(X_train,y_train, verbose=0)\n",
    "print('loss of train set: {:0.3f}'.format(scores[0]))\n",
    "print('accuracy of train set: {:0.1f}%'.format(scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Save and load the final model to JSON or YAML ** https://keras.io/getting-started/faq/#how-can-i-save-a-keras-model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 1) JSON **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model in model.json, model.h5\n"
     ]
    }
   ],
   "source": [
    "# save model as JSON\n",
    "filename = 'model'\n",
    "# model architecture\n",
    "model_json = model.to_json()\n",
    "with open(filename+'.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "# model weghts\n",
    "model.save(filename+'.h5')\n",
    "print('Saved model in',filename+'.json,',filename+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#del model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from model.json, model.h5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 12)                372       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 485\n",
      "Trainable params: 485\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#load model from JSON\n",
    "filename = 'model'\n",
    "# model architecture\n",
    "from keras.models import model_from_json\n",
    "json_file = open(filename+'.json', 'r')\n",
    "model_json = json_file.read()\n",
    "json_file.close()\n",
    "model = model_from_json(model_json)\n",
    "# model weghts\n",
    "model.load_weights(filename+'.h5')\n",
    "print('Loaded model from',filename+'.json,',filename+'.h5')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss of test set: 0.131\n",
      "accuracy of test set: 97.4%\n"
     ]
    }
   ],
   "source": [
    "# evaluate loaded model on test data\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy',metrics=['accuracy'])\n",
    "scores = model.evaluate(X_test,y_test,verbose=0)\n",
    "print('loss of test set: {:0.3f}'.format(scores[0]))\n",
    "print('accuracy of test set: {:0.1f}%'.format(scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** 2) YAML **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model in model.yaml, model.h5\n"
     ]
    }
   ],
   "source": [
    "# save model as YAML\n",
    "filename = 'model'\n",
    "# model architecture\n",
    "model_yaml= model.to_yaml()\n",
    "with open(filename+'.yaml', 'w') as yaml_file:\n",
    "    yaml_file.write(model_yaml)\n",
    "# model weghts\n",
    "model.save(filename+'.h5')\n",
    "print('Saved model in',filename+'.yaml,',filename+'.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model from model.yaml, model.h5\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 12)                372       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 104       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 485\n",
      "Trainable params: 485\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#load model from YAML\n",
    "filename = 'model'\n",
    "# model architecture\n",
    "from keras.models import model_from_yaml\n",
    "yaml_file = open(filename+'.json', 'r')\n",
    "model_yaml = yaml_file.read()\n",
    "yaml_file.close()\n",
    "model = model_from_yaml(model_yaml)\n",
    "# model weghts\n",
    "model.load_weights(filename+'.h5')\n",
    "print('Loaded model from',filename+'.yaml,',filename+'.h5')\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss of test set: 0.131\n",
      "accuracy of test set: 97.4%\n"
     ]
    }
   ],
   "source": [
    "# evaluate loaded model on test data\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy',metrics=['accuracy'])\n",
    "scores = model.evaluate(X_test,y_test,verbose=0)\n",
    "print('loss of test set: {:0.3f}'.format(scores[0]))\n",
    "print('accuracy of test set: {:0.1f}%'.format(scores[1]*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Classification report & Confusion Matrix **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      1.00      0.99       285\n",
      "          1       1.00      0.98      0.99       170\n",
      "\n",
      "avg / total       0.99      0.99      0.99       455\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKwAAACsCAYAAADmMUfYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nFA+sC8r/A0j+8Nvh6/NAAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b13321d518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,classification_report,accuracy_score\n",
    "#classification report\n",
    "print(classification_report(y_train, model.predict_classes(X_train,verbose=0)))\n",
    "\n",
    "#confusion matrix\n",
    "confmat = confusion_matrix(y_train, model.predict_classes(X_train,verbose=0))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(2.5, 2.5))\n",
    "ax.matshow(confmat, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(confmat.shape[0]):\n",
    "    for j in range(confmat.shape[1]):\n",
    "        ax.text(x=j, y=i, s=confmat[i, j], va='center', ha='center')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation with Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.4%\n"
     ]
    }
   ],
   "source": [
    "# predict class with test set (new, unseen)\n",
    "y_pred = model.predict_classes(X_test,verbose=0)\n",
    "print('Accuracy: {:0.1f}%'.format(accuracy_score(y_test,y_pred)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      1.00      0.98        72\n",
      "          1       1.00      0.93      0.96        42\n",
      "\n",
      "avg / total       0.97      0.97      0.97       114\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAKwAAACsCAYAAADmMUfYAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nigfWBcUD64LigXVB8cC6oPw/zRzOL0MyGdUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1b132fcc390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#classification report\n",
    "print(classification_report(y_test, model.predict_classes(X_test,verbose=0)))\n",
    "\n",
    "#confusion matrix\n",
    "confmat = confusion_matrix(y_test, model.predict_classes(X_test,verbose=0))\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(2.5, 2.5))\n",
    "ax.matshow(confmat, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(confmat.shape[0]):\n",
    "    for j in range(confmat.shape[1]):\n",
    "        ax.text(x=j, y=i, s=confmat[i, j], va='center', ha='center')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.ylabel('True label')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "- Model Architecture: Input + hidden1(12nodes) + hidden2(8nodes) + output\n",
    "\n",
    "    \n",
    "- Best params: epochs=30, batch_size=16, optimizer='adam',kernel_initializer='uniform', activation='tanh'\n",
    "    \n",
    "    \n",
    "- Accuracy of test set: ** 97.4% ** (tie with SVM)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
